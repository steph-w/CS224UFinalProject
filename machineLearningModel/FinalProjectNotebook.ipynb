{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS224U Final Project\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__authors__ = \"Stephanie Wang, Megha Srivastava, Sarai Gould\"\n",
    "__version__=\"CS224u, Stanford, Spring 2016 term\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import scipy.stats\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "##### Features\n",
    "The input to these functions is a list of features to train on. Ideally this is a list of dictionaries.\n",
    "We are using unigrams as out features, for which we have sparse vector representations for each sentence in the text. We are also using the dependency parses as a feature set. \n",
    "##### Binary Classification\n",
    "We are looking at binary tasks -- classifying as either male/ female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(reader, vectorizer=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    reader : iterator\n",
    "        This is the dataset that we are featurizing\n",
    "        \n",
    "    vectorizer : sklearn.feature_extraction.DictVectorizer\n",
    "        If this is None, then a new `DictVectorizer` is created and\n",
    "        used to turn the list of dicts created by `phi` into a \n",
    "        feature matrix. This happens when we are training.\n",
    "\n",
    "        If this is not None, then it's assumed to be a `DictVectorizer` \n",
    "        and used to transform the list of dicts. This happens in \n",
    "        assessment, when we take in new instances and need to \n",
    "        featurize them as we did in training.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dict with keys 'X' (the feature matrix), 'y' (the list of labels), \n",
    "        'vectorizer' (the 'DictVectorizer'), and 'raw_examples'(for error analysis).\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    feat_dicts = []\n",
    "    raw_examples = []\n",
    "    for sentence, label in reader:\n",
    "        #What if the sentence contains both male and female?\n",
    "        labels.append(label)\n",
    "        feat_dicts.append(sentence)\n",
    "        #raw_examples.append()\n",
    "    feat_matrix = None\n",
    "    #In training, we want a new vectorizer:\n",
    "    if vectorizer == None:\n",
    "        vectorizer = DictVectorizer(sparse=True)\n",
    "        feat_matrix = vectorizer.fit_transform(feat_dicts)\n",
    "    #In assessment, we featurize using the existing vectorizer:\n",
    "    else:\n",
    "        feat_matrix = vectorizer.fit_transform(feat_dicts)\n",
    "    return {'X': feat_matrix,\n",
    "            'y': labels,\n",
    "            'vectorizer': vectorizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_maxent_classifier(X, y):    \n",
    "    \"\"\"Wrapper for `sklearn.linear.model.LogisticRegression`. This is also \n",
    "    called a Maximum Entropy (MaxEnt) Classifier, which is more fitting \n",
    "    for the multiclass case.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.\n",
    "        \n",
    "    y : list\n",
    "        The list of labels for rows in `X`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sklearn.linear.model.LogisticRegression\n",
    "        A trained `LogisticRegression` instance.\n",
    "    \n",
    "    \"\"\"\n",
    "    mod = LogisticRegression(fit_intercept=True)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experiment(\n",
    "            train_reader=None,\n",
    "            assess_reader=None,\n",
    "            train_size=0.7,\n",
    "            train_func=fit_maxent_classifier,\n",
    "            score_func=utils.safe_macro_f1,\n",
    "            verbose=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ==========\n",
    "    train_reader : Iterator for training data.\n",
    "    \n",
    "    assess_reader : Iterator for assessment data.\n",
    "    \n",
    "    train_size : float\n",
    "        If 'assess_reader' is None, then this is percentage of \n",
    "        'train_reader' devoted to training. Else this is ignored.\n",
    "    train_func : model wrapper\n",
    "        Any function taking in a feature matrix and label list\n",
    "        and returns a fitted model with a 'predict' function\n",
    "        that operates on feature matrices.\n",
    "    score_metric : Scoring function, default is weighted average F1\n",
    "    verbose : bool\n",
    "        Whether to print out model assessment to standard output.\n",
    "    \n",
    "    Prints\n",
    "    ======\n",
    "    Model accuracy and model precision/recall/F1 report.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    Float\n",
    "        Overall scoring metric determined by 'score_metric'.\n",
    "    \"\"\"\n",
    "    # Train dataset:\n",
    "    train = build_dataset(train_reader, vectorizer=None)\n",
    "    #Manage the assessment set-up:\n",
    "    X_train = train['X']\n",
    "    y_train = train['y']\n",
    "    X_assess = None\n",
    "    y_assess = None\n",
    "    if assess_reader == None:\n",
    "        #'train_test_split' is a sklearn function that splits arrays or matrices into random train and test subsets\n",
    "        X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "                X_train, y_train, train_size=train_size)\n",
    "    else:\n",
    "        #Assessment dataset using the training vectorizer:\n",
    "        assess = build_dataset(assess_reader, vectorizer=None)\n",
    "        X_assess, y_assess = assess['X'], assess['y']\n",
    "    #Train:\n",
    "    mod = train_func(X_train, y_train)\n",
    "    #Predictions:\n",
    "    predictions = mod.predict(X_assess)\n",
    "    #Report:\n",
    "    if verbose:\n",
    "        print('Accuracy: %0.03f' % accuracy_score(y_assess, predictions))\n",
    "        print(classification_report(y_assess, predictions, digits=3))\n",
    "    # Return the overall score:\n",
    "    return score_func(y_assess, predictions) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-57a212f88755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-fee7253d0c26>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(train_reader, assess_reader, train_size, train_func, score_func, verbose)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \"\"\"\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Train dataset:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;31m#Manage the assessment set-up:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b61584ad359d>\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(reader, vectorizer)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfeat_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mraw_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m#What if the sentence contains both male and female?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "_ = experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
