{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS224U Final Project: Analysis of Gender Roles and Bias in Literary Portrayal of Characters\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__authors__ = \"Stephanie Wang, Megha Srivastava, Sarai Gould\"\n",
    "__version__=\"CS224u, Stanford, Spring 2016 term\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from pandas import DataFrame\n",
    "import scipy.stats\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "##### Features\n",
    "The input to these functions is a list of features to train on. Ideally this is a list of dictionaries which can then be dictvectorized into a feature matrix. \n",
    "Current features:\n",
    " - Unigrams\n",
    " - Dependencies\n",
    " - Genres\n",
    " - Date of Publication\n",
    " - Sentence Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs \n",
    "\n",
    "#labels are: Male Char, Female Auth: MCFA; Female Char, Female Auth: FCFA; Male Char, Male Auth: MCMA;\n",
    "#Female Char, Male Auth: FCMA; Male Char, Female Char, Female Auth: MCFCFA; Male Char, Female Char Male Auth: MCFCMA\n",
    "def train_file_reader(src_filename):\n",
    "    curr_author_gender = \"FA\"\n",
    "    curr_genre = \"Default_Genre\"\n",
    "    curr_pub = \"0000\"\n",
    "    all_lines_file = codecs.open(src_filename, 'r', 'utf8')\n",
    "    iterable_file = iter(all_lines_file)\n",
    "    for line in iterable_file:\n",
    "        if \"#####\" in line:   \n",
    "            #line represents a new book in the dataset, indicating a change in author gender, pub year, and genre\n",
    "            if \"GENDER:MALE\" in line:\n",
    "                curr_author_gender = \"MA\"\n",
    "            else:\n",
    "                curr_author_gender = \"FA\"\n",
    "            pub_year_pattern = re.compile('#PUB:(\\d+)#') #extracts publication year\n",
    "            pub_matches = pub_year_pattern.findall(line)\n",
    "            if pub_matches:\n",
    "                curr_pub = pub_matches[0]\n",
    "            genre_pattern = re.compile('#GENRE:(.+)#PUB') #extracts genre\n",
    "            genre_matches = genre_pattern.findall(line)\n",
    "            if genre_matches:\n",
    "                curr_genre = genre_matches[0]\n",
    "        if line.startswith(\"SENTENCE: \"): #sentence to label\n",
    "            label = \"\"\n",
    "            if \"00MALE00\" in line:\n",
    "                label += \"MC\"\n",
    "            if \"00FEMALE00\" in line:\n",
    "                label += \"FC\"\n",
    "            if label == \"\":\n",
    "                continue\n",
    "            label += curr_author_gender\n",
    "            unigrams_list = []\n",
    "            for word in line.split(\" \"):\n",
    "                if (not (\"00MALE00\" in word) and not (\"00FEMALE00\" in word) and not (word.startswith(\"SENTENCE:\"))):\n",
    "                    unigrams_list.append(word) #gets all unigrams except those obviously indicating gender\n",
    "            unigrams_length = len(unigrams_list) #gets the length of sentence\n",
    "            dependency_list = []\n",
    "            line = next(iterable_file)\n",
    "            if line.startswith(\"DEPENDENCY: \"): #dependencies corresponding to above sentence\n",
    "                for dep in line.split(\" \"):\n",
    "                    if (dep != \"DEPENDENCY:\"):\n",
    "                        dependency_list.append(dep)\n",
    "            if not dependency_list:\n",
    "                continue\n",
    "            yield(unigrams_list, unigrams_length, dependency_list, curr_pub, curr_genre, label) #returns a generator\n",
    "        \n",
    "def train_reader():\n",
    "    #hard-code file HERE\n",
    "    return train_file_reader(\"all_files_lines_deps.txt.v3\")    \n",
    "\n",
    "def features_phi(unigrams, length, dependencies, pub, genre):\n",
    "    features_list = []\n",
    "    features_list.extend(unigrams)\n",
    "    features_list.extend(dependencies)\n",
    "    features_list.append(length)\n",
    "    #publication date feature is currently divided into buckets by century. Change this code to \n",
    "    #use buckets of decades, centuries, etc. \n",
    "    if pub.startswith(\"18\"):\n",
    "        features_list.append(\"1800\")\n",
    "    elif pub.startswith(\"19\"):\n",
    "        features_list.append(\"1900\")\n",
    "    elif pub.startswith(\"17\"):\n",
    "        features_list.append(\"1700\")\n",
    "    elif pub.startswith(\"16\"):\n",
    "        features_list.append(\"1600\")\n",
    "    else:\n",
    "        features_list.append(\"0000\")\n",
    "    #appends genre feature\n",
    "    features_list.append(genre)\n",
    "    #turns feature list into a dictionary\n",
    "    return Counter(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(reader, phi, vectorizer=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    reader : iterator\n",
    "        This is the dataset that we are featurizing\n",
    "        \n",
    "    vectorizer : sklearn.feature_extraction.DictVectorizer\n",
    "        If this is None, then a new `DictVectorizer` is created and\n",
    "        used to turn the list of dicts created by `phi` into a \n",
    "        feature matrix. This happens when we are training.\n",
    "\n",
    "        If this is not None, then it's assumed to be a `DictVectorizer` \n",
    "        and used to transform the list of dicts. This happens in \n",
    "        assessment, when we take in new instances and need to \n",
    "        featurize them as we did in training.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dict with keys 'X' (the feature matrix), 'y' (the list of labels), \n",
    "        'vectorizer' (the 'DictVectorizer'), and 'raw_examples'(for error analysis).\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    feat_dicts = []\n",
    "    for unigrams, length, deps, pub, genre, label in reader():\n",
    "        if genre != \"ChildrensFiction\":\n",
    "            continue\n",
    "        labels.append(label)\n",
    "        feat_dicts.append(phi(unigrams, length, deps, pub, genre))\n",
    "    feat_matrix = None\n",
    "    #In training, we want a new vectorizer:\n",
    "    if vectorizer == None:\n",
    "        vectorizer = DictVectorizer(sparse=True)\n",
    "        feat_matrix = vectorizer.fit_transform(feat_dicts)\n",
    "        feat_names = vectorizer.get_feature_names()\n",
    "    #In assessment, we featurize using the existing vectorizer:\n",
    "    else:\n",
    "        feat_matrix = vectorizer.fit_transform(feat_dicts)\n",
    "    \n",
    "    return {'X': feat_matrix,\n",
    "            'y': labels,\n",
    "            'featureNames': feat_names,\n",
    "            'vectorizer': vectorizer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the classifier on our feature matrix and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_maxent_classifier(X, y):    \n",
    "    \"\"\"Wrapper for `sklearn.linear.model.LogisticRegression`. This is also \n",
    "    called a Maximum Entropy (MaxEnt) Classifier, which is more fitting \n",
    "    for the multiclass case.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.\n",
    "        \n",
    "    y : list\n",
    "        The list of labels for rows in `X`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sklearn.linear.model.LogisticRegression\n",
    "        A trained `LogisticRegression` instance.\n",
    "    \n",
    "    \"\"\"\n",
    "    mod = LogisticRegression(fit_intercept=True)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment to train and test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experiment(\n",
    "            train_reader=train_reader,\n",
    "            assess_reader=None,\n",
    "            train_size=0.7,\n",
    "            phi = features_phi,\n",
    "            train_func=fit_maxent_classifier,\n",
    "            score_func=utils.safe_macro_f1,\n",
    "            verbose=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ==========\n",
    "    train_reader : Iterator for training data.\n",
    "    \n",
    "    assess_reader : Iterator for assessment data.\n",
    "    \n",
    "    train_size : float\n",
    "        If 'assess_reader' is None, then this is percentage of \n",
    "        'train_reader' devoted to training. Else this is ignored.\n",
    "    train_func : model wrapper\n",
    "        Any function taking in a feature matrix and label list\n",
    "        and returns a fitted model with a 'predict' function\n",
    "        that operates on feature matrices.\n",
    "    score_metric : Scoring function, default is weighted average F1\n",
    "    verbose : bool\n",
    "        Whether to print out model assessment to standard output.\n",
    "    \n",
    "    Prints\n",
    "    ======\n",
    "    Model accuracy and model precision/recall/F1 report.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    Float\n",
    "        Overall scoring metric determined by 'score_metric'.\n",
    "    \"\"\"\n",
    "    # Train dataset:\n",
    "    train = build_dataset(train_reader, phi, vectorizer=None)\n",
    "    #Manage the assessment set-up:\n",
    "    X_train = train['X']\n",
    "    y_train = train['y']\n",
    "    feature_names = train['featureNames']\n",
    "    X_assess = None\n",
    "    y_assess = None\n",
    "    if assess_reader == None:\n",
    "        #'train_test_split' is a sklearn function that splits arrays or matrices into random train and test subsets\n",
    "        X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "                X_train, y_train, train_size=train_size)\n",
    "    else:\n",
    "        #Assessment dataset using the training vectorizer:\n",
    "        assess = build_dataset(assess_reader, phi, vectorizer=None)\n",
    "        X_assess, y_assess = assess['X'], assess['y']\n",
    "    #Train:\n",
    "    mod = train_func(X_train, y_train)\n",
    "    #Predictions:\n",
    "    predictions = mod.predict(X_assess)\n",
    "    #Print features and feature weights\n",
    "    coef = np.matrix(mod.coef_)\n",
    "    df = DataFrame(coef.transpose(), index = feature_names)\n",
    "    print('Feature names and their weights:')\n",
    "    print (df.sort_values([1], ascending=[False]))\n",
    "    #Report:\n",
    "    if verbose:\n",
    "        print('Accuracy: %0.03f' % accuracy_score(y_assess, predictions))\n",
    "        print(classification_report(y_assess, predictions, digits=3))\n",
    "    # Return the overall score:\n",
    "    return score_func(y_assess, predictions) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_classifier_with_crossvalidation(X, y, basemod, cv, param_grid, scoring='accuracy'):\n",
    "    #Find the best model within param_grid:\n",
    "    crossvalidator = GridSearchCV(basemod, param_grid, cv=cv, scoring=scoring)\n",
    "    crossvalidator.fit(X, y)\n",
    "    print(\"Best params\", crossvalidator.best_params_)\n",
    "    print(\"Best score: %0.03f\" % crossvalidator.best_score_)\n",
    "    return crossvalidator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_maxent_with_crossvalidation(X, y):\n",
    "    basemod = LogisticRegression()\n",
    "    cv = 5\n",
    "    param_grid = {'fit_intercept': [True, False],\n",
    "                 'C': [0.4, 0.6, 0.8, 1.0, 2.0, 3.0, 0.9, 0.5],\n",
    "                 'penalty': ['l1', 'l2']}\n",
    "    return fit_classifier_with_crossvalidation(X, y, basemod, cv, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = experiment(\n",
    "        train_func=fit_classifier_with_crossvalidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
