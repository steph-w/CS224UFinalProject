{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS224U Final Project: Analysis of Gender Roles and Bias in Literary Portrayal of Characters\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__authors__ = \"Stephanie Wang, Megha Srivastava, Sarai Gould\"\n",
    "__version__=\"CS224u, Stanford, Spring 2016 term\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import scipy.stats\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "##### Features\n",
    "The input to these functions is a list of features to train on. Ideally this is a list of dictionaries.\n",
    "We are using unigrams as our features, for which we have sparse vector representations for each sentence in the text. We are also using the dependency parses as a feature set. \n",
    "##### Binary Classification\n",
    "We are looking at binary tasks -- classifying as either male/ female\n",
    "##### Train and Test\n",
    "We need to split our data into two different sets -- one for training our classifier, and one for testing the model for accuracy.\n",
    "#### TO DO:\n",
    " - Add a function to read in the features as a tuple -- (dictionary, label) where dictionary is the dictionary for a sentence, and label is \"female\" or \"male\".\n",
    " - Account for the fact that a sentence could have both male and female labels\n",
    " - Add hyperparameter tuning for better results. Try out other classification models for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs \n",
    "\n",
    "#labels are: Male Char, Female Auth: MCFA; Female Char, Female Auth: FCFA; Male Char, Male Auth: MCMA;\n",
    "#Female Char, Male Auth: FCMA; Male Char, Female Char, Female Auth: MCFCFA; Male Char, Female Char Male Auth: MCFCMA\n",
    "def train_file_reader(src_filename):\n",
    "    curr_author_gender = \"FA\"\n",
    "    curr_genre = \"Default_Genre\"\n",
    "    curr_pub = \"0000\"\n",
    "    all_lines_file = codecs.open(src_filename, 'r', 'utf8')\n",
    "    iterable_file = iter(all_lines_file)\n",
    "    for line in iterable_file:\n",
    "        if \"#####\" in line:   \n",
    "            #line represents a new book in the dataset, indicating a change in author gender, pub year, and genre\n",
    "            if \"GENDER:MALE\" in line:\n",
    "                curr_author_gender = \"MA\"\n",
    "            else:\n",
    "                curr_author_gender = \"FA\"\n",
    "            pub_year_pattern = re.compile('#PUB:(\\d+)#') #extracts publication year\n",
    "            pub_matches = pub_year_pattern.findall(line)\n",
    "            if pub_matches:\n",
    "                curr_pub = pub_matches[0]\n",
    "            genre_pattern = re.compile('#GENRE:(.+)#PUB') #extracts genre\n",
    "            genre_matches = genre_pattern.findall(line)\n",
    "            if genre_matches:\n",
    "                curr_genre = genre_matches[0]\n",
    "        if line.startswith(\"SENTENCE: \"): #sentence to label\n",
    "            label = \"\"\n",
    "            if \"00MALE00\" in line:\n",
    "                label += \"MC\"\n",
    "            if \"00FEMALE00\" in line:\n",
    "                label += \"FC\"\n",
    "            if label == \"\":\n",
    "                continue\n",
    "            label += curr_author_gender\n",
    "            unigrams_list = []\n",
    "            for word in line.split(\" \"):\n",
    "                if (word != \"00MALE00\" and word != \"00FEMALE00\" and word != \"SENTENCE:\"):\n",
    "                    unigrams_list.append(word) #gets all unigrams except those obviously indicating gender\n",
    "            dependency_list = []\n",
    "            line = next(iterable_file)\n",
    "            if line.startswith(\"DEPENDENCY: \"): #dependencies corresponding to above sentence\n",
    "                for dep in line.split(\" \"):\n",
    "                    if (dep != \"DEPENDENCY:\"):\n",
    "                        dependency_list.append(dep)\n",
    "            if not dependency_list:\n",
    "                continue\n",
    "            yield(unigrams_list, dependency_list, curr_pub, curr_genre, label) #returns a generator\n",
    "        \n",
    "def train_reader():\n",
    "    #hard-code file HERE\n",
    "    return train_file_reader(\"replaced_all_lines.txt.sentences.extracted.dep\")    \n",
    "\n",
    "def features_phi(unigrams, dependencies, pub, genre):\n",
    "    features_list = []\n",
    "    features_list.extend(unigrams)\n",
    "    features_list.extend(dependencies)\n",
    "    #publication date feature is currently divided into buckets by century. Change this code to \n",
    "    #use buckets of decades, centuries, etc. \n",
    "    if pub.startswith(\"18\"):\n",
    "        features_list.append(\"1800\")\n",
    "    elif pub.startswith(\"19\"):\n",
    "        features_list.append(\"1900\")\n",
    "    elif pub.startswith(\"17\"):\n",
    "        features_list.append(\"1700\")\n",
    "    elif pub.startswith(\"16\"):\n",
    "        features_list.append(\"1600\")\n",
    "    else:\n",
    "        features_list.append(\"0000\")\n",
    "    #appends genre feature\n",
    "    features_list.append(genre)\n",
    "    #turns feature list into a dictionary\n",
    "    return Counter(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(reader, phi, vectorizer=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    reader : iterator\n",
    "        This is the dataset that we are featurizing\n",
    "        \n",
    "    vectorizer : sklearn.feature_extraction.DictVectorizer\n",
    "        If this is None, then a new `DictVectorizer` is created and\n",
    "        used to turn the list of dicts created by `phi` into a \n",
    "        feature matrix. This happens when we are training.\n",
    "\n",
    "        If this is not None, then it's assumed to be a `DictVectorizer` \n",
    "        and used to transform the list of dicts. This happens in \n",
    "        assessment, when we take in new instances and need to \n",
    "        featurize them as we did in training.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dict with keys 'X' (the feature matrix), 'y' (the list of labels), \n",
    "        'vectorizer' (the 'DictVectorizer'), and 'raw_examples'(for error analysis).\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    feat_dicts = []\n",
    "    raw_examples = []\n",
    "    for unigrams, deps, pub, genre, label in reader():\n",
    "        labels.append(label)\n",
    "        feat_dicts.append(phi(unigrams, deps, pub, genre))\n",
    "        raw_examples.append(phi(unigrams, deps, pub, genre))\n",
    "    feat_matrix = None\n",
    "    #In training, we want a new vectorizer:\n",
    "    if vectorizer == None:\n",
    "        vectorizer = DictVectorizer(sparse=True)\n",
    "        feat_matrix = vectorizer.fit_transform(feat_dicts)\n",
    "    #In assessment, we featurize using the existing vectorizer:\n",
    "    else:\n",
    "        feat_matrix = vectorizer.fit_transform(feat_dicts)\n",
    "    return {'X': feat_matrix,\n",
    "            'y': labels,\n",
    "            'examples': raw_examples,\n",
    "            'vectorizer': vectorizer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the classifier on our feature matrix and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_maxent_classifier(X, y):    \n",
    "    \"\"\"Wrapper for `sklearn.linear.model.LogisticRegression`. This is also \n",
    "    called a Maximum Entropy (MaxEnt) Classifier, which is more fitting \n",
    "    for the multiclass case.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2d np.array\n",
    "        The matrix of features, one example per row.\n",
    "        \n",
    "    y : list\n",
    "        The list of labels for rows in `X`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sklearn.linear.model.LogisticRegression\n",
    "        A trained `LogisticRegression` instance.\n",
    "    \n",
    "    \"\"\"\n",
    "    mod = LogisticRegression(fit_intercept=True)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment to train and test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experiment(\n",
    "            train_reader=train_reader,\n",
    "            assess_reader=None,\n",
    "            train_size=0.7,\n",
    "            phi = features_phi,\n",
    "            train_func=fit_maxent_classifier,\n",
    "            score_func=utils.safe_macro_f1,\n",
    "            verbose=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ==========\n",
    "    train_reader : Iterator for training data.\n",
    "    \n",
    "    assess_reader : Iterator for assessment data.\n",
    "    \n",
    "    train_size : float\n",
    "        If 'assess_reader' is None, then this is percentage of \n",
    "        'train_reader' devoted to training. Else this is ignored.\n",
    "    train_func : model wrapper\n",
    "        Any function taking in a feature matrix and label list\n",
    "        and returns a fitted model with a 'predict' function\n",
    "        that operates on feature matrices.\n",
    "    score_metric : Scoring function, default is weighted average F1\n",
    "    verbose : bool\n",
    "        Whether to print out model assessment to standard output.\n",
    "    \n",
    "    Prints\n",
    "    ======\n",
    "    Model accuracy and model precision/recall/F1 report.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    Float\n",
    "        Overall scoring metric determined by 'score_metric'.\n",
    "    \"\"\"\n",
    "    # Train dataset:\n",
    "    train = build_dataset(train_reader, phi, vectorizer=None)\n",
    "    #Manage the assessment set-up:\n",
    "    X_train = train['X']\n",
    "    y_train = train['y']\n",
    "    raw_examples = train['examples']\n",
    "    X_assess = None\n",
    "    y_assess = None\n",
    "    if assess_reader == None:\n",
    "        #'train_test_split' is a sklearn function that splits arrays or matrices into random train and test subsets\n",
    "        X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "                X_train, y_train, train_size=train_size)\n",
    "    else:\n",
    "        #Assessment dataset using the training vectorizer:\n",
    "        assess = build_dataset(assess_reader, phi, vectorizer=None)\n",
    "        X_assess, y_assess = assess['X'], assess['y']\n",
    "    #Train:\n",
    "    mod = train_func(X_train, y_train)\n",
    "    #Predictions:\n",
    "    predictions = mod.predict(X_assess)\n",
    "    #Print features and feature weights\n",
    "    #print(raw_examples)\n",
    "    print(X_train)\n",
    "    print(mod.coef_)\n",
    "    #Report:\n",
    "    if verbose:\n",
    "        print('Accuracy: %0.03f' % accuracy_score(y_assess, predictions))\n",
    "        print(classification_report(y_assess, predictions, digits=3))\n",
    "    # Return the overall score:\n",
    "    return score_func(y_assess, predictions) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 82747)\t1.0\n",
      "  (0, 82555)\t1.0\n",
      "  (0, 82530)\t1.0\n",
      "  (0, 81976)\t1.0\n",
      "  (0, 81191)\t1.0\n",
      "  (0, 81182)\t1.0\n",
      "  (0, 81071)\t1.0\n",
      "  (0, 81024)\t1.0\n",
      "  (0, 80942)\t1.0\n",
      "  (0, 80940)\t1.0\n",
      "  (0, 80911)\t1.0\n",
      "  (0, 80520)\t1.0\n",
      "  (0, 80477)\t1.0\n",
      "  (0, 80447)\t1.0\n",
      "  (0, 80329)\t8.0\n",
      "  (0, 80240)\t2.0\n",
      "  (0, 80239)\t2.0\n",
      "  (0, 80234)\t1.0\n",
      "  (0, 80231)\t2.0\n",
      "  (0, 80227)\t1.0\n",
      "  (0, 80225)\t5.0\n",
      "  (0, 80222)\t8.0\n",
      "  (0, 80219)\t1.0\n",
      "  (0, 80168)\t2.0\n",
      "  (0, 80048)\t1.0\n",
      "  :\t:\n",
      "  (1786, 49678)\t1.0\n",
      "  (1786, 48994)\t1.0\n",
      "  (1786, 48521)\t1.0\n",
      "  (1786, 45226)\t1.0\n",
      "  (1786, 45217)\t1.0\n",
      "  (1786, 41464)\t1.0\n",
      "  (1786, 38097)\t1.0\n",
      "  (1786, 28802)\t1.0\n",
      "  (1786, 27889)\t1.0\n",
      "  (1786, 23319)\t1.0\n",
      "  (1786, 16289)\t1.0\n",
      "  (1786, 15169)\t1.0\n",
      "  (1786, 14920)\t1.0\n",
      "  (1786, 10366)\t2.0\n",
      "  (1786, 8507)\t1.0\n",
      "  (1786, 8172)\t1.0\n",
      "  (1786, 2581)\t1.0\n",
      "  (1786, 1605)\t1.0\n",
      "  (1786, 821)\t2.0\n",
      "  (1786, 436)\t1.0\n",
      "  (1786, 216)\t1.0\n",
      "  (1786, 174)\t1.0\n",
      "  (1786, 73)\t1.0\n",
      "  (1786, 17)\t5.0\n",
      "  (1786, 6)\t1.0\n",
      "[[-0.50857845  0.25927449 -0.00470112 ..., -0.00146086 -0.01953722\n",
      "   0.30020515]\n",
      " [-0.11903408 -0.01647409 -0.01912831 ..., -0.01074987 -0.00394597\n",
      "  -0.0243734 ]\n",
      " [ 0.55728929 -0.3074389   0.0178077  ...,  0.01071072  0.02353475\n",
      "  -0.28850621]]\n",
      "Accuracy: 0.742\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FCMA      0.615     0.186     0.286       129\n",
      "     MCFCMA      0.614     0.273     0.378        99\n",
      "       MCMA      0.757     0.961     0.847       539\n",
      "\n",
      "avg / total      0.715     0.742     0.692       767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Use Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_classifier_with_crossvalidation(X, y, basemod, cv, param_grid, scoring='accuracy'):\n",
    "    #Find the best model within param_grid:\n",
    "    crossvalidator = GridSearchCV(basemod, param_grid, cv=cv, scoring=scoring)\n",
    "    crossvalidator.fit(X, y)\n",
    "    print(\"Best params\", crossvalidator.best_params_)\n",
    "    print(\"Best score: %0.03f\" % crossvalidator.best_score_)\n",
    "    return crossvalidator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_maxent_with_crossvalidation(X, y):\n",
    "    basemod = LogisticRegression()\n",
    "    cv = 5\n",
    "    param_grid = {'fit_intercept': [True, False],\n",
    "                 'C': [0.4, 0.6, 0.8, 1.0, 2.0, 3.0],\n",
    "                 'penalty': ['11', '12']}\n",
    "    return fit_classifier_with_crossvalidation(X, y, basemod, cv, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/svm/base.py:874: DeprecationWarning: penalty='11' has been deprecated in favor of penalty='11' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported set of arguments: The combination of penalty='11' and loss='logistic_regression' is not supported, Parameters: penalty='11', loss='logistic_regression', dual=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-9c2525c646b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m _ = experiment(\n\u001b[0;32m----> 2\u001b[0;31m         train_func=fit_maxent_with_crossvalidation)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-56cef4986afb>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(train_reader, assess_reader, train_size, phi, train_func, score_func, verbose)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mX_assess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_assess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massess\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massess\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m#Train:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;31m#Predictions:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_assess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-90bdaeb117a9>\u001b[0m in \u001b[0;36mfit_maxent_with_crossvalidation\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                  'penalty': ['11', '12']}\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfit_classifier_with_crossvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasemod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-95481ff0d2dd>\u001b[0m in \u001b[0;36mfit_classifier_with_crossvalidation\u001b[0;34m(X, y, basemod, cv, param_grid, scoring)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#Find the best model within param_grid:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcrossvalidator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasemod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcrossvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best params\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrossvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best score: %0.03f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcrossvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1152\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                 self.max_iter, self.tol, self.random_state)\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0;31m# LibLinear wants targets as doubles, even for classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0my_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0msolver_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[1;32m    914\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stephaniewang/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_get_liblinear_solver_type\u001b[0;34m(multi_class, penalty, loss, dual)\u001b[0m\n\u001b[1;32m    767\u001b[0m     raise ValueError('Unsupported set of arguments: %s, '\n\u001b[1;32m    768\u001b[0m                      \u001b[0;34m'Parameters: penalty=%r, loss=%r, dual=%r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                      % (error_string, penalty, loss, dual))\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported set of arguments: The combination of penalty='11' and loss='logistic_regression' is not supported, Parameters: penalty='11', loss='logistic_regression', dual=False"
     ]
    }
   ],
   "source": [
    "_ = experiment(\n",
    "        train_func=fit_maxent_with_crossvalidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
